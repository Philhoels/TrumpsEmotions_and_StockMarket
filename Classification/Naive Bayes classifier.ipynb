{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is going to be the second classifier I´m going to use. \n",
    "The multinomial naive bayes classifier was part of lab 5 in our course. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed libaries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>09.02.20 00:47</td>\n",
       "      <td>13459</td>\n",
       "      <td>72445</td>\n",
       "      <td>A great coach and a fantastic guy. His endorse...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>08.02.20 22:08</td>\n",
       "      <td>47880</td>\n",
       "      <td>215503</td>\n",
       "      <td>Pete Rose played Major League Baseball for 24 ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>08.02.20 20:48</td>\n",
       "      <td>9452</td>\n",
       "      <td>37402</td>\n",
       "      <td>Total and complete Endorsement for Debbie Lesk...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>08.02.20 20:40</td>\n",
       "      <td>17545</td>\n",
       "      <td>62484</td>\n",
       "      <td>Governor Cuomo wanted to see me this weekend. ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>08.02.20 20:01</td>\n",
       "      <td>27437</td>\n",
       "      <td>120598</td>\n",
       "      <td>We will not be touching your Social Security o...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>31.01.20 03:54</td>\n",
       "      <td>24418</td>\n",
       "      <td>100133</td>\n",
       "      <td>This November, we are going to defeat the Radi...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>31.01.20 03:48</td>\n",
       "      <td>19539</td>\n",
       "      <td>88388</td>\n",
       "      <td>Thank you Iowa, I love you! https://www. pscp....</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>31.01.20 01:19</td>\n",
       "      <td>18878</td>\n",
       "      <td>73498</td>\n",
       "      <td>Great poll in Iowa, where I just landed for a ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>30.01.20 23:04</td>\n",
       "      <td>22964</td>\n",
       "      <td>138237</td>\n",
       "      <td>Working closely with China and others on Coron...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>30.01.20 22:58</td>\n",
       "      <td>12210</td>\n",
       "      <td>75152</td>\n",
       "      <td>Leaving Michigan now, great visit, heading for...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           username            date  retweets  favorites  \\\n",
       "0   realDonaldTrump  09.02.20 00:47     13459      72445   \n",
       "1   realDonaldTrump  08.02.20 22:08     47880     215503   \n",
       "2   realDonaldTrump  08.02.20 20:48      9452      37402   \n",
       "3   realDonaldTrump  08.02.20 20:40     17545      62484   \n",
       "4   realDonaldTrump  08.02.20 20:01     27437     120598   \n",
       "..              ...             ...       ...        ...   \n",
       "86  realDonaldTrump  31.01.20 03:54     24418     100133   \n",
       "87  realDonaldTrump  31.01.20 03:48     19539      88388   \n",
       "88  realDonaldTrump  31.01.20 01:19     18878      73498   \n",
       "89  realDonaldTrump  30.01.20 23:04     22964     138237   \n",
       "90  realDonaldTrump  30.01.20 22:58     12210      75152   \n",
       "\n",
       "                                                 text  emotion  \n",
       "0   A great coach and a fantastic guy. His endorse...      joy  \n",
       "1   Pete Rose played Major League Baseball for 24 ...  sadness  \n",
       "2   Total and complete Endorsement for Debbie Lesk...      joy  \n",
       "3   Governor Cuomo wanted to see me this weekend. ...  sadness  \n",
       "4   We will not be touching your Social Security o...    anger  \n",
       "..                                                ...      ...  \n",
       "86  This November, we are going to defeat the Radi...      joy  \n",
       "87  Thank you Iowa, I love you! https://www. pscp....      joy  \n",
       "88  Great poll in Iowa, where I just landed for a ...      joy  \n",
       "89  Working closely with China and others on Coron...      joy  \n",
       "90  Leaving Michigan now, great visit, heading for...      joy  \n",
       "\n",
       "[91 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "data = pd.read_csv(\"LabeledTweets.csv\", \";\")\n",
    "data = data.drop([\"Unnamed: 0\", \"index\", \"emotion_probability\"], axis = 1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop([\"emotion\", \"username\", \"date\", \"retweets\", \"favorites\"], axis = 1)\n",
    "y = data[\"emotion\"]\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the dictionary\n",
    "dict_fit = {}\n",
    "\n",
    "for index in range(X_train.shape[0]):\n",
    "    \n",
    "    # set up the pipeline\n",
    "\n",
    "    # create pipeline\n",
    "    Pipeline_CV_MNB = Pipeline([\n",
    "        ('vect', CountVectorizer(lowercase=True)),\n",
    "        ('clf', MultinomialNB()),\n",
    "    ])\n",
    "    \n",
    "    # fit every mention\n",
    "    # fit the pipeline with X (mention) & y (entity)\n",
    "    fit = Pipeline_CV_MNB.fit(X = [X_train.iloc[index][0]],\n",
    "                              y = [y_train.iloc[index]])\n",
    "    \n",
    "    dict_fit[index] = fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-5d63d0600c03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_fit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "for index in X_test.shape[0]:\n",
    "    print(dict_fit.predict([X_test.iloc[index][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Don’t worry, it won’t happen! https:// twitter.com/TuckerCarlson/ status/1225607709044637697 …'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create predictions\n",
    "def prob6_func(df):\n",
    "    # run every row of the df\n",
    "    for row in range(df.shape[0]):\n",
    "        # want to make predictions from df of problem 3\n",
    "        # we gonna label the --NME-- of df_dev_small\n",
    "\n",
    "        # we have to access the mention for each sentence in the df_dev_small\n",
    "        sentence = df.iloc[row,1].split()\n",
    "\n",
    "        # we need the beginning and the end to access the mention\n",
    "        beg = df.iloc[row,2]\n",
    "        end = df.iloc[row,3]\n",
    "        mention = sentence[beg:end]\n",
    "\n",
    "        # we also need to access the context, which is needed to make the prediction of the mention\n",
    "        # 5 tokens to the left and the 5 tokens to the right of the mention\n",
    "        context = sentence_test[max(0,(beg-5)):min((end+5), len(sentence))]\n",
    "        # need the context as string for the prediction\n",
    "        context_string = \" \".join(context)\n",
    "\n",
    "        ### ------ flag ------\n",
    "\n",
    "        # create df, later check if mention exists\n",
    "        mention_test_string = \" \".join(mention)\n",
    "        mention_df = df_contexts[df_contexts.mention == mention_test_string]\n",
    "\n",
    "        # if df not empty -> take highest prob\n",
    "        # else -- NME --\n",
    "        if mention_df.shape[0] != 0:\n",
    "            # make predictions\n",
    "            label = dict_fit[mention_test_string].predict([context_string])[0]\n",
    "            yield mention_test_string, label\n",
    "        else:\n",
    "            yield mention_test_string, \"--NME--\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
